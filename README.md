# Facial-emotion-Recognition(얼굴 감정 인식)

## 프로젝트 개요
**얼굴 감정 인식(Facial Emotion Recognition, FER)** 프로젝트는 컴퓨터 비전과 인공지능 기술을 활용하여 사람의 얼굴 표정을 분석하고 그로부터 감정을 추정하는 기술 및 시스템을 개발하는 것을 말합니다.
이런 기술을 통해 보안 및 감시, 의료 및 심리치료, 마케팅 및 소비자 분석, 고객 서비스 및 자동차 산업 등 다양한 산업에서 여러 문제를 해결할 수 있는 강력한 도구입니다. 이를 통해 보다 안전하고, 효과적이며, 개인화된 서비스를 제공할 수 있으며, 인간-기계 상호작용의 질을 크게 향상시킬 수 있습니다.

## **필요 라이브러리 및 프로그램**

1.Python: 코드를 실행하는 기본 환경.

2.TensorFlow/Keras: 딥러닝 모델을 구축하고 학습하는 데 사용됩니다.

* TensorFlow는 버전 2.x 이상을 권장합니다.

* Keras는 TensorFlow에 포함되어 있으므로 별도로 설치할 필요는 없습니다.

3.OpenCV: 컴퓨터 비전 작업을 수행하는 라이브러리.

4.DeepFace: 얼굴 감정 인식을 수행하는 라이브러리.

5.Matplotlib: 학습 결과를 시각화하는 데 사용됩니다.

6.Numpy: 수치 계산 및 배열 조작을 위한 라이브러리.

7.Google Colab: 코드를 실행할 수 있는 클라우드 기반 환경 (또는 로컬 환경).


## 추후 개선 사항
얼굴 감정 인식에 있어서 응용 분야에 따라 실시간으로 감정을 인식하면서 성능이 높게 나와야 하지만 60%의 정확도에 그쳐 나의 프로젝트 같은 경우 지속적으로 성능 부분을 개선해야 한다고 생각한다.

또한 우리나라 사람의 얼굴 뿐만 아니라 다양한 인종, 성별, 나이를 포함한 데이터를 확보해야 모델의 일반화 성능이 향상된다는 점과 개인의 프라이버시와 데이터 사용에 관한 윤리적 문제를 고려해야 한다는 점에서 얼굴 감정 인식의 한계점을 확인할 수 있.


-----
## 데이터 세트
**Kaggle - FER2013**

이미지에서 표정 학습
데이터세트 정보
데이터는 48x48픽셀의 회색조 얼굴 이미지로 구성됩니다. 얼굴은 자동으로 등록되어 얼굴이 어느 정도 중앙에 위치하고 각 이미지에서 거의 동일한 공간을 차지합니다.

FER2013의 과제 얼굴 표정에 나타난 감정을 기반으로 각 얼굴을 7가지 범주(0=화남, 1=혐오, 2=두려움, 3=행복, 4=슬픔, 5=놀람, 6=보통) 중 하나로 분류하는 것입니다. 훈련 세트는 28,709개의 예시로 구성되어 있으며, 공개 테스트 세트는 3,589개의 예시로 구성되어 있습니다.

## 모델 설명
기본적으로 다양한 모델을 사용했으나 결과가 가장 높게 나왔던 

이 모델은 입력 이미지에서 특징을 추출하고, 이를 기반으로 감정 클래스를 예측하는 CNN 모델입니다. 여러 Conv2D와 MaxPooling2D 레이어를 통해 특징을 추출하고, Fully Connected 레이어를 통해 감정을 분류합니다. Dropout 레이어를 추가하여 과적합을 방지하고 모델의 일반화 성능을 높였습니다.

## 실험 결과
모델 평가에 사용된 지표는 accuracy와 f1 score가 있습니다. 그래프는

![epochs10batch32](https://github.com/hyeoni0525/Facial-emotion-Recognition/assets/170999814/0c15e09e-a24e-4e02-8d7d-699e281df0de)
***

![곽철이](곽철이.png)
